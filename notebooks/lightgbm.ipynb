{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    ids = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        while 1:\n",
    "            try:\n",
    "                d = pickle.load(f)\n",
    "                features = []\n",
    "                for from_tok, to_tok in itertools.product(['A', 'B', 'P'], repeat=2):\n",
    "                    if from_tok != to_tok:\n",
    "                        lb = from_tok + to_tok\n",
    "                        if len(d[lb]) == 0:\n",
    "                            break\n",
    "                        max_att = d[lb][0]\n",
    "                        for att in d[lb][1:]:\n",
    "                            max_att = np.maximum(max_att, att)\n",
    "                        d[lb] = max_att\n",
    "                        features.append(max_att.flatten())\n",
    "                if len(d[lb]) == 0:\n",
    "                    continue\n",
    "                labels.append(d['label'])\n",
    "                ids.append(d['ID'])\n",
    "                data.append(np.concatenate(features))\n",
    "            except EOFError:\n",
    "                break\n",
    "    return ids, data, labels\n",
    "\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    x = x - x.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    return y / y.sum(axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "LABEL_TO_INT = {'A': 0, 'B': 1, 'Neither': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_train1, X_train1, Y_train1 = get_data('../data/large-atts-mgap-validation.pkl')\n",
    "IDs_train2, X_train2, Y_train2 = get_data('../data/large-atts-mgap-test.pkl')\n",
    "IDs_train = IDs_train1 + IDs_train2\n",
    "X_train = X_train1 + X_train2\n",
    "Y_train = Y_train1 + Y_train2\n",
    "IDs_test, X_test, Y_test = get_data('../data/large-atts-mgap-development.pkl')\n",
    "Y_train = [LABEL_TO_INT[y] for y in Y_train]\n",
    "Y_test = [LABEL_TO_INT[y] for y in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2454, 2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2454, 2304) (2000, 2304)\n",
      "FOLD # 0 Log Loss: 0.27223 - 0.28475\n",
      "Model Runtime: 0.94 Minutes\n",
      "FOLD # 1 Log Loss: 0.31708 - 0.28848\n",
      "Model Runtime: 0.90 Minutes\n",
      "FOLD # 2 Log Loss: 0.32548 - 0.29182\n",
      "Model Runtime: 0.90 Minutes\n",
      "FOLD # 3 Log Loss: 0.30772 - 0.28774\n",
      "Model Runtime: 0.90 Minutes\n",
      "FOLD # 4 Log Loss: 0.34796 - 0.29443\n",
      "Model Runtime: 0.82 Minutes\n",
      "Loss folds [0.2722298799505061, 0.31708409932120973, 0.32547661697333713, 0.30771756904606656, 0.3479556276601703]\n",
      "Test log loss: 0.28587\n"
     ]
    }
   ],
   "source": [
    "NTRAIN, NTEST = len(X_train), len(X_test)\n",
    "X, y = np.array(X_train), np.array(Y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(Y_test)\n",
    "print(X.shape, X_test.shape)\n",
    "N_CLASSES = 3\n",
    "EARLY_STOPPING = 300\n",
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': N_CLASSES,\n",
    "    'metric': 'multi_logloss',\n",
    "    # 'max_depth': 15,\n",
    "    'num_leaves': 127,\n",
    "    'feature_fraction': 0.2,\n",
    "    # 'bagging_fraction': 0.8,\n",
    "    # 'bagging_freq': 5,\n",
    "    'learning_rate': 0.02,\n",
    "    'lambda_l1': 0.0,\n",
    "    'lambda_l2': 0.0,\n",
    "    'verbose': -1,\n",
    "    'nthread': 12\n",
    "}\n",
    "\n",
    "KFOLD, SHUF, RS = 5, True, 123\n",
    "OOF_TRAIN = np.zeros((NTRAIN, N_CLASSES))\n",
    "OOF_TEST = np.zeros((NTEST, N_CLASSES))\n",
    "val_score_list = []\n",
    "kf = StratifiedKFold(n_splits=KFOLD, shuffle=SHUF, random_state=RS)\n",
    "# dtest = xgb.DMatrix(data=X_test)\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(\"FOLD #\", i, end=' ')\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X[val_idx], y[val_idx]\n",
    "\n",
    "    lgtrain = lgb.Dataset(X_train, y_train)\n",
    "    lgvalid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "    modelstart = time.time()\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgvalid],\n",
    "        valid_names=['valid'],\n",
    "        early_stopping_rounds=EARLY_STOPPING,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    val_preds = lgb_clf.predict(X_valid)\n",
    "    err = log_loss(y_valid, val_preds)\n",
    "    test_preds = lgb_clf.predict(X_test, raw_score=True)\n",
    "    test_preds = softmax(test_preds, axis=1)\n",
    "    err_test = log_loss(y_test, test_preds)\n",
    "    OOF_TEST += test_preds\n",
    "    val_preds = lgb_clf.predict(X_valid, raw_score=True)\n",
    "    val_preds = softmax(val_preds, axis=1)\n",
    "    OOF_TRAIN[val_idx] = val_preds\n",
    "\n",
    "    print('Log Loss: %.5f - %.5f' % (err, err_test))\n",
    "    val_score_list.append(err)\n",
    "    print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "\n",
    "OOF_TEST /= KFOLD\n",
    "print(\"Loss folds\", val_score_list)\n",
    "print(\"Test log loss: %.5f\" % log_loss(y_test, OOF_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission_stage_1.csv', index_col='ID')\n",
    "\n",
    "for _id, pred in zip(IDs_test, OOF_TEST):\n",
    "    submission.loc[_id, 'A'] = pred[0]\n",
    "    submission.loc[_id, 'B'] = pred[1]\n",
    "    submission.loc[_id, 'NEITHER'] = pred[2]\n",
    "submission.to_csv('../output/lightgbm-mgap.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
